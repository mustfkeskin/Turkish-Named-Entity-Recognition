{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "train_path = \"../Data/NER_data/BIO_EOS_Train.txt\"\n",
    "test_path = \"../Data/NER_data/BIO_EOS_Test.txt\"\n",
    "\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(train_path, sep= \"\\t\", header=None)\n",
    "df_train.columns = [\"words\", \"labels\"]\n",
    "df_train.dropna(inplace=True)\n",
    "\n",
    "'''\n",
    "\n",
    "df_test = pd.read_csv(test_path, sep= \"\\t\", header=None)\n",
    "df_test.columns = [\"words\", \"labels\"]\n",
    "df_test.dropna(inplace=True)\n",
    "\n",
    "'''\n",
    "\n",
    "df = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 12920/12920 [03:49<00:00, 56.28it/s]\n"
     ]
    }
   ],
   "source": [
    "df[\"sentence_idx\"] = -1\n",
    "\n",
    "last_index = 0\n",
    "mini_df = df[df.words == \"EOS\"]\n",
    "for i in tqdm(range(mini_df.shape[0])):\n",
    "    df.loc[last_index : mini_df.index.values[i], \"sentence_idx\"] = i\n",
    "    last_index =  mini_df.index.values[i] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>labels</th>\n",
       "      <th>sentence_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260176</th>\n",
       "      <td>kamuoyu</td>\n",
       "      <td>O</td>\n",
       "      <td>12918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260177</th>\n",
       "      <td>yoklamalarına</td>\n",
       "      <td>O</td>\n",
       "      <td>12918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260178</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td>12918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260179</th>\n",
       "      <td>Kohl</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>12918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260181</th>\n",
       "      <td>'ün</td>\n",
       "      <td>O</td>\n",
       "      <td>12918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260182</th>\n",
       "      <td>rakibi</td>\n",
       "      <td>O</td>\n",
       "      <td>12918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260183</th>\n",
       "      <td>Sosyal</td>\n",
       "      <td>O</td>\n",
       "      <td>12918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260184</th>\n",
       "      <td>Demokrat</td>\n",
       "      <td>O</td>\n",
       "      <td>12918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260185</th>\n",
       "      <td>Gerhard</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>12918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260186</th>\n",
       "      <td>Schröder</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>12918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260188</th>\n",
       "      <td>4</td>\n",
       "      <td>O</td>\n",
       "      <td>12918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260189</th>\n",
       "      <td>puan</td>\n",
       "      <td>O</td>\n",
       "      <td>12918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260190</th>\n",
       "      <td>önde</td>\n",
       "      <td>O</td>\n",
       "      <td>12918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260191</th>\n",
       "      <td>EOS</td>\n",
       "      <td>O</td>\n",
       "      <td>12918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260192</th>\n",
       "      <td>Ancak</td>\n",
       "      <td>O</td>\n",
       "      <td>12919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260193</th>\n",
       "      <td>kararsızların</td>\n",
       "      <td>O</td>\n",
       "      <td>12919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260194</th>\n",
       "      <td>sayısı</td>\n",
       "      <td>O</td>\n",
       "      <td>12919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260195</th>\n",
       "      <td>da</td>\n",
       "      <td>O</td>\n",
       "      <td>12919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260196</th>\n",
       "      <td>büyük</td>\n",
       "      <td>O</td>\n",
       "      <td>12919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260197</th>\n",
       "      <td>EOS</td>\n",
       "      <td>O</td>\n",
       "      <td>12919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                words  labels  sentence_idx\n",
       "260176        kamuoyu       O         12918\n",
       "260177  yoklamalarına       O         12918\n",
       "260178              ,       O         12918\n",
       "260179           Kohl  PERSON         12918\n",
       "260181            'ün       O         12918\n",
       "260182         rakibi       O         12918\n",
       "260183         Sosyal       O         12918\n",
       "260184       Demokrat       O         12918\n",
       "260185        Gerhard  PERSON         12918\n",
       "260186       Schröder  PERSON         12918\n",
       "260188              4       O         12918\n",
       "260189           puan       O         12918\n",
       "260190           önde       O         12918\n",
       "260191            EOS       O         12918\n",
       "260192          Ancak       O         12919\n",
       "260193  kararsızların       O         12919\n",
       "260194         sayısı       O         12919\n",
       "260195             da       O         12919\n",
       "260196          büyük       O         12919\n",
       "260197            EOS       O         12919"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        self.n_sent = 1\n",
    "        self.dataset = dataset\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"words\"].values.tolist(),\n",
    "                                                       #s['pos'].values.tolist(),\n",
    "                                                        s[\"labels\"].values.tolist())]\n",
    "        self.grouped = self.dataset.groupby(\"sentence_idx\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(df)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Müzik'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txts = []\n",
    "txt = \"\"\n",
    "for j in range(len(sentences)):\n",
    "    for i in range(len(sentences[j]) - 1):\n",
    "        txt = txt + \" \" + sentences[j][i][0]\n",
    "        txts.append(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = max([len(s) for s in sentences])\n",
    "print ('Maximum sequence length:', maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how long sentences are so that we can pad them\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.hist([len(s) for s in sentences], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(df[\"words\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "n_words = len(words);\n",
    "n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = list(set(df[\"labels\"].values))\n",
    "n_tags = len(tags)\n",
    "n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(maxlen=140, sequences=X, padding=\"post\",value=n_words - 1)\n",
    "y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=140, sequences=y, padding=\"post\", value=tag2idx[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "\n",
    "input = Input(shape=(140,))\n",
    "model = Embedding(input_dim=n_words, output_dim=140, input_length=140)(input)\n",
    "model = Dropout(0.1)(model)\n",
    "model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(model)  # softmax output layer\n",
    "model = Model(input, out)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, np.array(y_train), batch_size=32, epochs=1, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "p = model.predict(np.array([X_test[i]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "print(\"{:15} ({:5}): {}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "for w,pred in zip(X_test[i],p[0]):\n",
    "    print(\"{:15}: {}\".format(words[w],tags[pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jpype\n",
    "\n",
    "def start_jvm_load_zemberek():\n",
    "    jpype.startJVM(\"C:/Program Files/Java/jre1.8.0_191/bin/server/jvm.dll\",\n",
    "         \"-Djava.class.path=../Other/zemberek_0_15.jar\", \"-ea\")\n",
    "\n",
    "    Tr = jpype.JClass(\"zemberek.morphology.TurkishMorphology\")\n",
    "    morphology = Tr.createWithDefaults()\n",
    "    return morphology\n",
    "\n",
    "        \n",
    "def jvm_shutdown():\n",
    "    jpype.shutdownJVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphology = start_jvm_load_zemberek()\n",
    "results = morphology.analyzeAndDisambiguate(\"nehirden atlarla atladık\").bestAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(results)):\n",
    "    word = results[i].surfaceForm()\n",
    "    pos = str(results[i].dictionaryItem.primaryPos)\n",
    "    print(word, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(results[i].)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
